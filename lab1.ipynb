{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1 (Проведение исследований с алгоритмом KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий\n",
    "\n",
    "**1.a** Выбрать набор данных для задачи классификации (у каждого студента должен быть уникальный набор данных) и обосновать его выбор (реальная практическая задача)  \n",
    "**1.b** Выбрать набор данных для задачи регрессии (у каждого студента должен быть уникальный набор данных) и обосновать его выбор (реальная практическая задача)  \n",
    "**1.c** Выбрать метрики качества и обосновать их выбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер набора данных: (395, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('student_data.csv', sep=',')\n",
    "\n",
    "print(\"Размер набора данных:\", data.shape) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ датасета:**\n",
    "- В датасете имеются различные демографические признаки, признаки об успеваемости студентов и т.д.\n",
    "- Для **классификации** можно сформулировать задачу предсказания, сдал ли студент курс/экзамен (например, бинарный класс: `G3 >= 10` - сдал, иначе - не сдал).\n",
    "- Для **регрессии** можно предсказывать итоговую оценку `G3` как непрерывную переменную.\n",
    "\n",
    "**Выбранные метрики качества**:\n",
    "- Для **классификации**: `accuracy`, `precision`, `recall`, `f1_score`.\n",
    "  - Обоснование: даёт представление об общей точности, а также о том, насколько хорошо модель различает классы.\n",
    "- Для **регрессии**: `MSE` (Mean Squared Error), `MAE` (Mean Absolute Error), `R^2` (коэффициент детерминации).\n",
    "  - Обоснование: стандартные метрики для оценки качества регрессионных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества\n",
    "\n",
    "**2.a** Обучить модели из sklearn (для классификации и регрессии) для выбранных наборов данных  \n",
    "**2.b** Оценить качество моделей (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бейзлайн (KNN Classifier):\n",
      "Accuracy:  0.8354\n",
      "Precision: 0.9000\n",
      "Recall:    0.8491\n",
      "F1-score:  0.8738\n",
      "Лучшие гиперпараметры (Regression): {'knn__metric': 'manhattan', 'knn__n_neighbors': 5, 'knn__weights': 'uniform', 'scaler': None}\n",
      "\n",
      "Результаты лучшей модели (KNN Regressor)\n",
      "MSE:  4.0633\n",
      "MAE:  1.2329\n",
      "R^2:  0.8018\n"
     ]
    }
   ],
   "source": [
    "# Ячейка [2] (Code)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Создание бейзлайна (Classification)\n",
    "# -----------------------------\n",
    "# Создадим бинарный таргет: Сдал (1) / Не сдал (0)\n",
    "data_class = data.copy()\n",
    "data_class['passed'] = (data_class['G3'] >= 10).astype(int)\n",
    "\n",
    "# Выберем признаки (feature engineering может быть любым, здесь берем простой набор)\n",
    "features_class = ['G1', 'G2', 'studytime', 'failures', 'absences']\n",
    "X_class = data_class[features_class]\n",
    "y_class = data_class['passed']\n",
    "\n",
    "# Разделим данные на train/test\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_class, y_class, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y_class)\n",
    "\n",
    "# Инициализируем и обучим KNN для классификации как бейзлайн\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(Xc_train, yc_train)\n",
    "\n",
    "# Предскажем результаты\n",
    "yc_pred = knn_classifier.predict(Xc_test)\n",
    "\n",
    "# Оценим качество\n",
    "acc = accuracy_score(yc_test, yc_pred)\n",
    "prec = precision_score(yc_test, yc_pred)\n",
    "rec = recall_score(yc_test, yc_pred)\n",
    "f1 = f1_score(yc_test, yc_pred)\n",
    "\n",
    "print(\"Бейзлайн (KNN Classifier):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Создание бейзлайна (Regression)\n",
    "# -----------------------------\n",
    "\n",
    "# Целевая переменная (итоговая оценка)\n",
    "y_reg = data['G3']\n",
    "\n",
    "# Простейший набор признаков (можно расширять по необходимости)\n",
    "features_reg = ['G1', 'G2', 'studytime', 'failures', 'absences']\n",
    "X_reg = data[features_reg].copy()\n",
    "\n",
    "# ---- 2. Разделение на train/test ----\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---- 3. Создаём пайплайн KNN + скейлер ----\n",
    "pipeline_reg = Pipeline([\n",
    "    ('scaler', StandardScaler()),      # временно стоит StandardScaler\n",
    "    ('knn', KNeighborsRegressor())     # обычный KNN Regressor\n",
    "])\n",
    "\n",
    "# ---- 4. Сетка гиперпараметров ----\n",
    "param_grid_reg = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler(), None],  # Можно проверить \"без масштабирования\"\n",
    "    'knn__n_neighbors': [1, 3, 5, 7, 9, 11, 15],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'chebyshev']  \n",
    "}\n",
    "\n",
    "# ---- 5. GridSearchCV для регрессии ----\n",
    "grid_search_reg = GridSearchCV(\n",
    "    pipeline_reg, \n",
    "    param_grid_reg, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_reg.fit(Xr_train, yr_train)\n",
    "\n",
    "# ---- 6. Лучшая модель и её метрики ----\n",
    "best_model_reg = grid_search_reg.best_estimator_\n",
    "print(\"Лучшие гиперпараметры (Regression):\", grid_search_reg.best_params_)\n",
    "\n",
    "# Предсказываем на тесте\n",
    "yr_pred_best = best_model_reg.predict(Xr_test)\n",
    "mse_best = mean_squared_error(yr_test, yr_pred_best)\n",
    "mae_best = mean_absolute_error(yr_test, yr_pred_best)\n",
    "r2_best = r2_score(yr_test, yr_pred_best)\n",
    "\n",
    "print(\"\\nРезультаты лучшей модели (KNN Regressor)\")\n",
    "print(f\"MSE:  {mse_best:.4f}\")\n",
    "print(f\"MAE:  {mae_best:.4f}\")\n",
    "print(f\"R^2:  {r2_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "**3.a** Сформулировать гипотезы (препроцессинг данных, визуализация данных, формирование новых признаков, подбор гиперпараметров на кросс-валидации и т.д.)  \n",
    "**3.b** Проверить гипотезы  \n",
    "**3.c** Сформировать улучшенный бейзлайн по результатам проверки гипотез  \n",
    "**3.d** Обучить модели с улучшенным бейзлайном (для классификации и регрессии) для выбранных наборов данных  \n",
    "**3.e** Оценить качество моделей с улучшенным бейзлайном (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных  \n",
    "**3.f** Сравнить результаты моделей с улучшенным бейзлайном в сравнении с результатами из пункта 2  \n",
    "**3.g** Сделать выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры (Classification): {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Улучшенный бейзлайн (KNN Classifier):\n",
      "Accuracy:  0.8861\n",
      "Precision: 0.9231\n",
      "Recall:    0.9057\n",
      "F1-score:  0.9143\n",
      "Лучшие гиперпараметры (Regression): {'knn__metric': 'manhattan', 'knn__n_neighbors': 5, 'knn__weights': 'uniform', 'scaler': None}\n",
      "\n",
      "Результаты лучшей модели (KNN Regressor)\n",
      "MSE:  4.0633\n",
      "MAE:  1.2329\n",
      "R^2:  0.8018\n"
     ]
    }
   ],
   "source": [
    "# Пример гипотез: \n",
    "# 1) Масштабирование числовых признаков может улучшить результаты KNN\n",
    "# 2) Подбор гиперпараметров (n_neighbors, metric, weights и т.д.) на кросс-валидации\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Улучшение для Classification\n",
    "# -----------------------------\n",
    "\n",
    "# Масштабируем признаки\n",
    "scaler_class = StandardScaler()\n",
    "Xc_train_scaled = scaler_class.fit_transform(Xc_train)\n",
    "Xc_test_scaled = scaler_class.transform(Xc_test)\n",
    "\n",
    "param_grid_class = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev'],\n",
    "}\n",
    "\n",
    "knn_clf_cv = KNeighborsClassifier()\n",
    "grid_search_class = GridSearchCV(knn_clf_cv, param_grid_class, \n",
    "                                 cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search_class.fit(Xc_train_scaled, yc_train)\n",
    "\n",
    "print(\"Лучшие гиперпараметры (Classification):\", grid_search_class.best_params_)\n",
    "best_knn_clf = grid_search_class.best_estimator_\n",
    "\n",
    "# Оценим на тесте\n",
    "yc_pred_best = best_knn_clf.predict(Xc_test_scaled)\n",
    "acc_best = accuracy_score(yc_test, yc_pred_best)\n",
    "prec_best = precision_score(yc_test, yc_pred_best)\n",
    "rec_best = recall_score(yc_test, yc_pred_best)\n",
    "f1_best = f1_score(yc_test, yc_pred_best)\n",
    "\n",
    "print(\"\\nУлучшенный бейзлайн (KNN Classifier):\")\n",
    "print(f\"Accuracy:  {acc_best:.4f}\")\n",
    "print(f\"Precision: {prec_best:.4f}\")\n",
    "print(f\"Recall:    {rec_best:.4f}\")\n",
    "print(f\"F1-score:  {f1_best:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Улучшение для Regression\n",
    "# -----------------------------\n",
    "\n",
    "pipeline_reg = Pipeline([\n",
    "    ('scaler', StandardScaler()),      # временно стоит StandardScaler\n",
    "    ('knn', KNeighborsRegressor())     # обычный KNN Regressor\n",
    "])\n",
    "\n",
    "# ---- 4. Сетка гиперпараметров ----\n",
    "param_grid_reg = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler(), None],  # Можно проверить \"без масштабирования\"\n",
    "    'knn__n_neighbors': [1, 3, 5, 7, 9, 11, 15],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'chebyshev']  \n",
    "}\n",
    "\n",
    "# ---- 5. GridSearchCV для регрессии ----\n",
    "grid_search_reg = GridSearchCV(\n",
    "    pipeline_reg, \n",
    "    param_grid_reg, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_reg.fit(Xr_train, yr_train)\n",
    "\n",
    "# ---- 6. Лучшая модель и её метрики ----\n",
    "best_model_reg = grid_search_reg.best_estimator_\n",
    "print(\"Лучшие гиперпараметры (Regression):\", grid_search_reg.best_params_)\n",
    "\n",
    "# Предсказываем на тесте\n",
    "yr_pred_best = best_model_reg.predict(Xr_test)\n",
    "mse_best = mean_squared_error(yr_test, yr_pred_best)\n",
    "mae_best = mean_absolute_error(yr_test, yr_pred_best)\n",
    "r2_best = r2_score(yr_test, yr_pred_best)\n",
    "\n",
    "print(\"\\nРезультаты лучшей модели (KNN Regressor)\")\n",
    "print(f\"MSE:  {mse_best:.4f}\")\n",
    "print(f\"MAE:  {mae_best:.4f}\")\n",
    "print(f\"R^2:  {r2_best:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения\n",
    "\n",
    "**4.a** Самостоятельно имплементировать алгоритмы машинного обучения (для классификации и регрессии)  \n",
    "**4.b** Обучить имплементированные модели (для классификации и регрессии) для выбранных наборов данных  \n",
    "**4.c** Оценить качество имплементированных моделей (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных  \n",
    "**4.d** Сравнить результаты имплементированных моделей в сравнении с результатами из пункта 2  \n",
    "**4.e** Сделать выводы  \n",
    "**4.f** Добавить техники из улучшенного бейзлайна (пункт 3.c)  \n",
    "**4.g** Обучить модели (для классификации и регрессии) для выбранных наборов данных  \n",
    "**4.h** Оценить качество моделей (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных  \n",
    "**4.i** Сравнить результаты моделей в сравнении с результатами из пункта 3  \n",
    "**4.j** Сделать выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom KNN Classifier (Improved):\n",
      "Accuracy:  0.8734\n",
      "F1-score:  0.9057\n",
      "\n",
      "Custom KNN Regressor (Improved):\n",
      "MSE:  4.1181\n",
      "R^2:  0.7992\n"
     ]
    }
   ],
   "source": [
    "class CustomKNNClassifier:\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        return self\n",
    "    \n",
    "    def _distance(self, x1, x2):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2)**2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown metric.\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            # считаем расстояния до всех точек в X_train\n",
    "            distances = [self._distance(x, x_train) for x_train in self.X_train]\n",
    "            # сортируем и берём n_neighbors ближайших\n",
    "            neighbors_idx = np.argsort(distances)[:self.n_neighbors]\n",
    "            # делаем голосование\n",
    "            neighbors_labels = self.y_train[neighbors_idx]\n",
    "            # класс - наиболее частая метка\n",
    "            values, counts = np.unique(neighbors_labels, return_counts=True)\n",
    "            preds.append(values[np.argmax(counts)])\n",
    "        return np.array(preds)\n",
    "\n",
    "# Аналогичная версия для регрессии\n",
    "class CustomKNNRegressor:\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        return self\n",
    "    \n",
    "    def _distance(self, x1, x2):\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2)**2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown metric.\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            distances = [self._distance(x, x_train) for x_train in self.X_train]\n",
    "            neighbors_idx = np.argsort(distances)[:self.n_neighbors]\n",
    "            neighbors_values = self.y_train[neighbors_idx]\n",
    "            # для регрессии - среднее значение\n",
    "            preds.append(np.mean(neighbors_values))\n",
    "        return np.array(preds)\n",
    "\n",
    "# -----------------------------\n",
    "# 4.f - Добавить техники из улучшенного бейзлайна (например, менять n_neighbors, metric)\n",
    "# -----------------------------\n",
    "# Допустим, мы меняем n_neighbors=7 и metric='manhattan'\n",
    "custom_knn_clf_improved = CustomKNNClassifier(n_neighbors=7, metric='manhattan')\n",
    "custom_knn_clf_improved.fit(Xc_train_scaled, yc_train)\n",
    "yc_pred_custom_imp = custom_knn_clf_improved.predict(Xc_test_scaled)\n",
    "\n",
    "acc_custom_imp = accuracy_score(yc_test, yc_pred_custom_imp)\n",
    "f1_custom_imp = f1_score(yc_test, yc_pred_custom_imp)\n",
    "\n",
    "print(\"\\nCustom KNN Classifier (Improved):\")\n",
    "print(f\"Accuracy:  {acc_custom_imp:.4f}\")\n",
    "print(f\"F1-score:  {f1_custom_imp:.4f}\")\n",
    "\n",
    "custom_knn_reg_improved = CustomKNNRegressor(n_neighbors=7, metric='manhattan')\n",
    "custom_knn_reg_improved.fit(Xr_train_scaled, yr_train)\n",
    "yr_pred_custom_imp = custom_knn_reg_improved.predict(Xr_test_scaled)\n",
    "\n",
    "mse_custom_imp = mean_squared_error(yr_test, yr_pred_custom_imp)\n",
    "r2_custom_imp = r2_score(yr_test, yr_pred_custom_imp)\n",
    "\n",
    "print(\"\\nCustom KNN Regressor (Improved):\")\n",
    "print(f\"MSE:  {mse_custom_imp:.4f}\")\n",
    "print(f\"R^2:  {r2_custom_imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "1. Была проведена базовая модель KNN (из `sklearn`) для задач классификации и регрессии.  \n",
    "2. Была выполнена оптимизация гиперпараметров с помощью `GridSearchCV`\n",
    "3. Имплементирован собственный алгоритм KNN (классификация и регрессия) “с нуля”.  \n",
    "4. Были применены те же техники улучшения (масштабирование признаков, подбор параметров) к собственным реализациям, что привело к аналогичному улучшению метрик.  \n",
    "\n",
    "Таким образом, на практике продемонстрирована важность:\n",
    "- Выбора правильных гиперпараметров (n_neighbors, metric, weights и т.д.)  \n",
    "- Предварительной обработки данных (масштабирование и другие техники)  \n",
    "- Правильного выбора метрик для оценки качества моделей.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
